{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb48c3f-bf53-40c2-8bf3-ef2e21e2f0fc",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5b3f8cf-95c8-44bf-8a90-a83e2abe8efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd477df2-4c39-4168-93ef-b148555c80ff",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d68f809-2640-48d5-8d8f-cf99fe0e374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessTweets:\n",
    "    def __init__(self):\n",
    "        self._stopwords = set(stopwords.words('english') + list(punctuation) + ['AT_USER', 'URL'])\n",
    "\n",
    "    def process_tweets(self, list_of_tweets):\n",
    "        processed_tweets = []\n",
    "        for tweet in list_of_tweets:\n",
    "            if tweet[\"label\"] is not None:\n",
    "                if tweet[\"label\"] == \"positive\" or tweet[\"label\"] == \"negative\":\n",
    "                    processed_tweets.append((self._process_tweet(tweet[\"text\"]), tweet[\"label\"]))\n",
    "            else:\n",
    "                processed_tweets.append((self._process_tweet(tweet[\"text\"]), None))\n",
    "\n",
    "        return processed_tweets\n",
    "\n",
    "    def _process_tweet(self, tweet):\n",
    "        tweet = tweet.lower()  # convert text to lower-case\n",
    "        tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', tweet)  # remove URLs\n",
    "        tweet = re.sub('@[^\\s]+', 'AT_USER', tweet)  # remove usernames\n",
    "        tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)  # remove the # in #hashtag\n",
    "        tweet = word_tokenize(tweet)  # remove repeated characters (helloooooooo into hello)\n",
    "\n",
    "        words = []\n",
    "        for word in tweet:\n",
    "            if word not in self._stopwords:\n",
    "                words.append(word)\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff2466aa-bfba-4f87-8813-657a51d8fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(preprocessed_training_data):\n",
    "    all_words = []\n",
    "\n",
    "    for (words, sentiment) in preprocessed_training_data:\n",
    "        all_words.extend(words)\n",
    "\n",
    "    wordlist = nltk.FreqDist(all_words)\n",
    "    word_features = wordlist.keys()\n",
    "\n",
    "    return word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f91b923-035e-4551-b253-7201942240d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tweet):\n",
    "    tweet_words = set(tweet)\n",
    "    features = {}\n",
    "    for word in training_data_features:\n",
    "        is_feature_in_words = word in tweet_words\n",
    "        features[word] = is_feature_in_words\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0db507-9eb4-4207-bc8d-a4235a89eaa6",
   "metadata": {},
   "source": [
    "### Load Tweet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e707b73-cd01-44fd-9def-bf8831ffc021",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "with open(\"tweetDataFile.csv\", 'rt', encoding='cp437') as csvfile:\n",
    "    lineReader = csv.reader(csvfile, delimiter=',', quotechar=\"\\\"\")\n",
    "    for row in lineReader:\n",
    "        tweet_data.append({\"tweet_id\": row[0], \"text\": row[1], \"label\": row[2], \"topic\": row[3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "282666b6-6d11-4143-bc63-f66a99e1be95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2935"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f29a9417-debe-45c6-9b53-c7d4fd55434b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tweet data =  2935\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(tweet_data)\n",
    "\n",
    "print(\"total tweet data = \", len(tweet_data))\n",
    "training_data_set = tweet_data[:2435]\n",
    "test_data_set = tweet_data[2435:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d786a4bf-9cb4-4180-87b2-2960f8828609",
   "metadata": {},
   "source": [
    "# Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a39763-435f-4458-aa1b-dbef60211b98",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "235fd5c6-3d02-406a-99d3-55ec614e4de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_processor = PreprocessTweets()\n",
    "preprocessed_training_set = tweet_processor.process_tweets(training_data_set)\n",
    "\n",
    "training_data_features = build_vocabulary(preprocessed_training_set)\n",
    "\n",
    "training_features = nltk.classify.apply_features(extract_features, preprocessed_training_set)\n",
    "\n",
    "NBayesClassifier = nltk.NaiveBayesClassifier.train(training_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656376f6-94a5-4178-9f0b-bc6339fccc5c",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e09a676-4d26-42ab-bab5-e7284861a867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Negative Sentiment\n",
      "Negative Sentiment Percentage = 56.64335664335665%\n"
     ]
    }
   ],
   "source": [
    "preprocessed_test_set = tweet_processor.process_tweets(test_data_set)\n",
    "\n",
    "classified_result_labels = []\n",
    "for tweet in preprocessed_test_set:\n",
    "    classified_result_labels.append(NBayesClassifier.classify(extract_features(tweet[0])))\n",
    "\n",
    "if classified_result_labels.count('positive') > classified_result_labels.count('negative'):\n",
    "    print(\"Overall Positive Sentiment\")\n",
    "    print(\"Positive Sentiment Percentage = \" + str(\n",
    "        100 * classified_result_labels.count('positive') / len(classified_result_labels)) + \"%\")\n",
    "else:\n",
    "    print(\"Overall Negative Sentiment\")\n",
    "    print(\"Negative Sentiment Percentage = \" + str(\n",
    "        100 * classified_result_labels.count('negative') / len(classified_result_labels)) + \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
